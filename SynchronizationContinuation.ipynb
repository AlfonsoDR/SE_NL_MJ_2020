{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import glob\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the full circuit model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thresh_exp(x):\n",
    "    '''Activation function'''\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def simulate_trial(ntrials=1000, duration=600, nstages=10, sigma=0, K=3.0, initI=0.7):\n",
    "    # Initial run\n",
    "    #ntrials = 1000\n",
    "    #duration = 600 #ms\n",
    "    #nstages = 10\n",
    "    PARAMS_DICT['sigma'] = sigma\n",
    "    PARAMS_DICT['K'] = K\n",
    "    \n",
    "    nbin = int(duration / PARAMS_DICT['dt'])\n",
    "\n",
    "    state_init = [np.ones(ntrials) * initI, \n",
    "                  np.ones(ntrials) * 0.7, \n",
    "                  np.ones(ntrials) * 0.2,\n",
    "                  np.ones(ntrials) * 0.5,\n",
    "                  0.0]\n",
    "\n",
    "    if nstages > 1:\n",
    "        ulst, vlst, ylst, Ilst, siglst = start_simulation_parallel(state_init, PARAMS_DICT, nbin)\n",
    "    else:\n",
    "        ulst, vlst, ylst, Ilst, siglst = start_simulation_parallel(state_init, PARAMS_DICT, 100)\n",
    "\n",
    "    # For subsequent runs, flip the state every 100 trials\n",
    "    for k in range((nstages - 2) * 2):\n",
    "        #acoefs = 1 - acoefs\n",
    "        state_init = [Ilst[-1], ulst[-1], vlst[-1], ylst[-1], (state_init[4] + 1.0)%2]\n",
    "        if state_init[4] == 0.0:\n",
    "            ulst2, vlst2, ylst2, Ilst2, siglst2 = start_simulation_parallel(state_init, PARAMS_DICT, nbin)\n",
    "        else:\n",
    "            ulst2, vlst2, ylst2, Ilst2, siglst2 = start_simulation_parallel(state_init, PARAMS_DICT, 1)\n",
    "\n",
    "        ulst += ulst2\n",
    "        vlst += vlst2\n",
    "        ylst += ylst2\n",
    "        Ilst += Ilst2\n",
    "        siglst += siglst2\n",
    "\n",
    "    if nstages > 1:\n",
    "        state_init = [Ilst[-1], ulst[-1], vlst[-1], ylst[-1], (state_init[4] + 1.0)%2]\n",
    "        # For the last run, produce the behavior when the threshold is reached\n",
    "        ulst2, vlst2, ylst2, Ilst2, siglst2 = start_simulation_parallel(state_init, PARAMS_DICT, 1)\n",
    "\n",
    "        ulst += ulst2\n",
    "        vlst += vlst2\n",
    "        ylst += ylst2\n",
    "        Ilst += Ilst2\n",
    "        siglst += siglst2\n",
    "        \n",
    "        state_init = [Ilst[-1], ulst[-1], vlst[-1], ylst[-1], (state_init[4] + 1.0)%2]\n",
    "        # For the last run, produce the behavior when the threshold is reached\n",
    "        ulst2, vlst2, ylst2, Ilst2, siglst2 = start_simulation_parallel(state_init, PARAMS_DICT, 200)\n",
    "\n",
    "        ulst += ulst2\n",
    "        vlst += vlst2\n",
    "        ylst += ylst2\n",
    "        Ilst += Ilst2\n",
    "        \n",
    "        siglst2[nbin] = 1\n",
    "        siglst += siglst2\n",
    "    else:\n",
    "        siglst[nbin] = 1\n",
    "        ylst2 = ylst\n",
    "\n",
    "    return ulst, vlst, ylst, Ilst, siglst, ylst2\n",
    "\n",
    "def plot_simulation_parallel(ulst, vlst, ylst, Ilst, siglst, params_dict):\n",
    "    '''Plot the simulations'''\n",
    "    dt = params_dict['dt']\n",
    "    nsteps = len(ulst)\n",
    "    tlst = np.arange(nsteps).astype('int')\n",
    "    sig_lst = np.floor(tlst / 100) % 2\n",
    "    sig_lst = sig_lst.astype('int')\n",
    "    \n",
    "    ulst_arr = np.array(ulst)\n",
    "    vlst_arr = np.array(vlst)\n",
    "    ylst_arr = np.array(ylst)\n",
    "    Ilst_arr = np.array(Ilst)\n",
    "    \n",
    "    wherelst = np.array(siglst) == 1.0\n",
    "    wherelst_shifted = np.concatenate((wherelst[1:], [False]))\n",
    "    wherelst += wherelst_shifted\n",
    "    \n",
    "    #wherelst2 = np.array(siglst) == 2.0\n",
    "\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(10, 10))\n",
    "    ax[0].plot(np.arange(nsteps) * dt, ulst_arr, 'b', alpha=0.2)\n",
    "    ax[0].set_ylabel('u')\n",
    "    ax[0].fill_between(np.arange(nsteps) * dt, np.min(np.array(ulst)), np.max(np.array(ulst)), where=wherelst, alpha=0.5)\n",
    "    #ax[0].fill_between(np.arange(nsteps) * dt, np.min(np.array(ulst)), np.max(np.array(ulst)), where=wherelst2, alpha=0.2)\n",
    "\n",
    "    ax[1].plot(np.arange(nsteps) * dt, vlst_arr, 'b', alpha=0.2)\n",
    "    ax[1].set_ylabel('v')\n",
    "    ax[1].fill_between(np.arange(nsteps) * dt, np.min(np.array(vlst)), np.max(np.array(vlst)), where=wherelst, alpha=0.5)\n",
    "    #ax[1].fill_between(np.arange(nsteps) * dt, np.min(np.array(vlst)), np.max(np.array(vlst)), where=wherelst2, alpha=0.2)\n",
    "\n",
    "    ax[2].plot(np.arange(nsteps) * dt, ylst_arr, 'b', alpha=0.2)\n",
    "    ax[2].set_ylabel('y')\n",
    "    ax[2].fill_between(np.arange(nsteps) * dt, np.min(np.array(ylst)), np.max(np.array(ylst)), where=wherelst, alpha=0.5)\n",
    "    #ax[2].fill_between(np.arange(nsteps) * dt, np.min(np.array(ylst)), np.max(np.array(ylst)), where=wherelst2, alpha=0.2)\n",
    "    ax[2].hlines(0.7, 0, nsteps * dt, linestyle='dotted')\n",
    "\n",
    "    ax[3].plot(np.arange(nsteps) * dt, Ilst_arr, 'b', alpha=0.2)\n",
    "    ax[3].set_ylabel('I')\n",
    "    ax[3].fill_between(np.arange(nsteps) * dt, np.min(np.array(Ilst)), np.max(np.array(Ilst)), where=wherelst, alpha=0.5)\n",
    "    #ax[3].fill_between(np.arange(nsteps) * dt, np.min(np.array(Ilst)), np.max(np.array(Ilst)), where=wherelst2, alpha=0.2)\n",
    "    ax[3].set_xlabel('Time (ms)');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARAMS_DICT = {'Wut': 6,\n",
    "              'Wuv': 6,\n",
    "              'Wvt': 6,\n",
    "              'Wvu': 6,\n",
    "              'dt': 10,\n",
    "              'tau': 100,\n",
    "              'ext': 0,\n",
    "              'y0': 0.7,\n",
    "              'IF': 100,\n",
    "              'uinit': 0.7,\n",
    "              'vinit': 0.2,\n",
    "              'yinit': 0.5,\n",
    "              'first_duration': 750}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dual_process_model_generalized(state_init, params, niter, durations, sigma, K, alpha):\n",
    "    '''\n",
    "    Inputs:\n",
    "    state_init: an array which includes:\n",
    "        * I: initial current\n",
    "        * u: initial state of u\n",
    "        * v: initial state of v\n",
    "        * y: initial state of y (readout neuron)\n",
    "        * sig: state indicator (0 or 1)\n",
    "        \n",
    "    params: a dictionary of relevant parameters\n",
    "    niter: number of iterations\n",
    "    \n",
    "    Outputs: each list contains niter elements\n",
    "    u_lst: list of u activities \n",
    "    v_lst: list of v activities\n",
    "    y_lst: list of y activities\n",
    "    I_lst: list of I activities\n",
    "    sig_lst: list of sig in this simulation\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Unpack parameters of the simulation\n",
    "    Wut = params['Wut']\n",
    "    Wuv = params['Wut']\n",
    "    Wvt = params['Wut']\n",
    "    Wvu = params['Wut']\n",
    "    dt = params['dt']\n",
    "    tau = params['tau']\n",
    "    ext = params['ext']\n",
    "    y0 = params['y0'] #The target (threshold) value of y\n",
    "    IF = params['IF']\n",
    "    \n",
    "    first_duration = PARAMS_DICT['first_duration']\n",
    "    nbinfirst = int(first_duration / dt)\n",
    "\n",
    "    \n",
    "    # Unpack variables\n",
    "    I, u, v, y, sig = state_init\n",
    "    \n",
    "    ntrials = len(I)\n",
    "    \n",
    "    I = I.copy()\n",
    "    uS = u.copy()\n",
    "    vS = v.copy()\n",
    "    yS = y.copy()\n",
    "    \n",
    "    IP = I.copy()\n",
    "    uP = u.copy()\n",
    "    vP = v.copy()\n",
    "    yP = y.copy()\n",
    "        \n",
    "    sig_lst = []\n",
    "    u_sim = []\n",
    "    v_sim = []\n",
    "    y_sim = []\n",
    "    I_lst = []\n",
    "    \n",
    "    u_p = []\n",
    "    v_p = []\n",
    "    y_p = []\n",
    "    I_p = []\n",
    "    production_lst = []\n",
    "    \n",
    "    durs = np.cumsum(np.divide(durations,dt))\n",
    "    durs = durs.astype(int)\n",
    "    \n",
    "    # Make the first duration constant\n",
    "    durs += (nbinfirst - durs[0])\n",
    "\n",
    "    #print(durs)\n",
    "    \n",
    "    for i in range(niter): \n",
    "        # First flash, no I update\n",
    "        if i == durs[0]:\n",
    "            #print(i, 'first flash')\n",
    "            sig = 1.0\n",
    "        elif any(i == durs):\n",
    "            sig = 1.0\n",
    "            I += (sig * K * (yS - y0)) / tau * dt\n",
    "            #print(i, 'flash')\n",
    "        else:\n",
    "            sig = 0.0\n",
    "            I += (sig * K * (yS - y0)) / tau * dt\n",
    "        \n",
    "        \n",
    "\n",
    "        # u-v and y update\n",
    "        uS += (-uS + thresh_exp(Wut * I - Wuv * vS - sig * IF + np.random.randn(ntrials) * sigma)) / tau * dt\n",
    "        vS += (-vS + thresh_exp(Wvt * I - Wvu * uS + sig * IF + np.random.randn(ntrials) * sigma)) / tau * dt\n",
    "        yS += (-yS + uS - vS + np.random.randn(ntrials) * sigma) / 100 * dt\n",
    "\n",
    "        v_sim.append(vS.copy())\n",
    "        u_sim.append(uS.copy())\n",
    "        y_sim.append(yS.copy())\n",
    "        I_lst.append(I.copy())\n",
    "        sig_lst.append(sig) \n",
    "        \n",
    "        \n",
    "        # u-v and y update\n",
    "        sigP = (yP >= y0).astype('float')\n",
    "        uP += (-uP + thresh_exp(Wut * IP - Wuv * vP - IF * sigP + np.random.randn(ntrials) * sigma)) / tau * dt\n",
    "        vP += (-vP + thresh_exp(Wvt * IP - Wvu * uP + IF * sigP + np.random.randn(ntrials) * sigma)) / tau * dt\n",
    "        yP += (-yP + uP - vP + np.random.randn(ntrials) * sigma) / tau * dt\n",
    "        \n",
    "        yPcurr = yP.copy()\n",
    "        yScurr = yS.copy()\n",
    "        \n",
    "        IP = I.copy() + alpha*(yP.copy() - yS.copy())\n",
    "\n",
    "        v_p.append(vP.copy())\n",
    "        u_p.append(uP.copy())\n",
    "        y_p.append(yP.copy())\n",
    "        I_p.append(IP.copy())\n",
    "        production_lst.append(sigP)\n",
    "        \n",
    "    return u_sim, v_sim, y_sim, I_lst, sig_lst, u_p, v_p, y_p, I_p, production_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_synchronization(sigma, K, initI, alpha, ntrials=1, durations=[600, 600, 600, 600, 1000, 600, 600]):\n",
    "    # Initial run\n",
    "    #ntrials = 1000\n",
    "    #duration = 600 #ms\n",
    "    #nstages = 10\n",
    "    \n",
    "    nbin = int(sum(np.divide(durations,PARAMS_DICT['dt'])))\n",
    "    \n",
    "    #print(nbin)\n",
    "    state_init = [np.ones(ntrials) * initI, \n",
    "                  np.ones(ntrials) * PARAMS_DICT['uinit'], \n",
    "                  np.ones(ntrials) * PARAMS_DICT['vinit'],\n",
    "                  np.ones(ntrials) * PARAMS_DICT['yinit'],\n",
    "                  0.0]\n",
    "\n",
    "    usim, vsim, ysim, Ilst, siglst, u_p, v_p, y_p, I_p, production_lst = dual_process_model_generalized(state_init, \n",
    "                                                                        PARAMS_DICT, nbin, durations, sigma, K, alpha)\n",
    "\n",
    "\n",
    "    return usim, vsim, ysim, Ilst, siglst, u_p, v_p, y_p, I_p, np.array(production_lst) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronization-continuation simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try to simulate the synchronization-continuation experiment, and compare the simulation to data provided by Evan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compare the result of the simulation to behavioral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulation ###\n",
    "durs = np.linspace(500, 850, 5)\n",
    "meanITIs = []\n",
    "\n",
    "for interval in durs:\n",
    "    usim, vsim, ysim, Ilst, siglst, u_p, v_p, y_p, I_p, production_lst = simulate_synchronization(ntrials=40, \n",
    "                                                                               durations=[interval] * 4 + [interval * 30],  \n",
    "                                                                               sigma=0.02, K=4, initI=0.76, alpha = 0.0)\n",
    "    \n",
    "    # Find the IPI (inter-production interval)\n",
    "    ipi_lst = []\n",
    "    for i in range(production_lst.shape[1]):\n",
    "        single_production = production_lst[:,i]\n",
    "        #print(len(np.nonzero(single_production)[0]))\n",
    "        ipi_lst.append(np.diff(np.nonzero(single_production)[0])[1:25])\n",
    "\n",
    "    meanline = np.mean(np.array(ipi_lst), axis=0)\n",
    "    meanITIs.append(meanline)\n",
    "\n",
    "meanITIs = np.array(meanITIs)\n",
    "bias_individual = meanITIs * 10 - durs[:,np.newaxis]\n",
    "bias_all = np.sum(bias_individual**2, axis=0)\n",
    "\n",
    "### Plotting ###\n",
    "palette = sns.color_palette('hls', 5)\n",
    "\n",
    "# Load the subjects' behavior \n",
    "filename = 'AL1_20180718_syncon_ITIs.mat'\n",
    "data = scipy.io.loadmat(filename)\n",
    "durs = data['durs'].flatten()\n",
    "splits = data['allDur_splits']\n",
    "IPI_mean = data['allDur_mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trials = splits[0,0]\n",
    "N = trials.shape[0]\n",
    "\n",
    "# Get number of taps for each trial\n",
    "ntaps = np.sum(~np.isnan(trials), axis=1)\n",
    "maxtaps = max(ntaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Simulation, with the correct number of trials ###\n",
    "#durs = np.linspace(500, 850, 5)\n",
    "meanITIs = []\n",
    "\n",
    "for interval in [550]:\n",
    "    usim, vsim, ysim, Ilst, siglst, u_p, v_p, y_p, I_p, production_lst = simulate_synchronization(ntrials=N, \n",
    "                                                                               durations=[interval] * 4 + [interval * (maxtaps + 3)],  \n",
    "                                                                               sigma=0.02, K=4, initI=0.76, alpha = 0.0)\n",
    "    \n",
    "    # Find the IPI (inter-production interval)\n",
    "    ipi_lst = []\n",
    "    for i in range(production_lst.shape[1]):\n",
    "        single_production = production_lst[:,i]\n",
    "        #print(len(np.nonzero(single_production)[0]))\n",
    "        tap_intervals = np.diff(np.nonzero(single_production)[0])[1:maxtaps].astype('float')\n",
    "        tap_intervals[ntaps[i]:] = np.nan\n",
    "        ipi_lst.append(tap_intervals)\n",
    "\n",
    "    meanline = np.nanmean(np.array(ipi_lst), axis=0)\n",
    "    meanITIs.append(meanline)\n",
    "\n",
    "IPIs = np.array(ipi_lst)\n",
    "meanITIs = np.array(meanITIs)\n",
    "bias_individual = meanITIs * 10 - durs[:,np.newaxis]\n",
    "bias_all = np.sum(bias_individual**2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_bias_all(IPI_mean, durs, tmax):\n",
    "    '''IPI_mean: an array of mean intervals\n",
    "    Returns the average bias profile across the different trial durations'''\n",
    "    Bias = np.zeros((tmax, 5))\n",
    "\n",
    "    for i in range(len(IPI_mean)):\n",
    "        IPI_single = IPI_mean[i].flatten()[:tmax]\n",
    "        bias_single = IPI_single - durs[i]\n",
    "        Bias[:,i] = bias_single\n",
    "\n",
    "    return np.sqrt(np.nanmean(Bias**2, axis=1)) * 1000\n",
    "\n",
    "def find_bias_arr(filename, tmax):\n",
    "    '''filename: SynCon_ITIs file name\n",
    "    tmax: max number of taps to consider\n",
    "    \n",
    "    Returns: the bias array, tmax x number of intervals in prior'''\n",
    "    data = scipy.io.loadmat(filename)\n",
    "    durs = data['durs'].flatten()\n",
    "    splits = data['allDur_splits']\n",
    "    IPI_mean = data['allDur_mean'][0]\n",
    "    \n",
    "    Bias = np.zeros((tmax, 5))\n",
    "\n",
    "    for i in range(len(IPI_mean)):\n",
    "        IPI_single = IPI_mean[i].flatten()[:tmax]\n",
    "        bias_single = IPI_single - durs[i]\n",
    "        Bias[:,i] = bias_single\n",
    "    \n",
    "    return Bias\n",
    "\n",
    "\n",
    "def find_std_arr(filename, tmax):\n",
    "    '''filename: SynCon_ITIs file name\n",
    "    tmax: max number of taps to consider\n",
    "    \n",
    "    Returns: the bias array, tmax x number of intervals in prior'''\n",
    "    data = scipy.io.loadmat(filename)\n",
    "    durs = data['durs'].flatten()\n",
    "    splits = data['allDur_splits']\n",
    "    IPI_std = data['allDur_std'][0]\n",
    "    \n",
    "    STD = np.zeros((tmax, 5))\n",
    "\n",
    "    for i in range(len(IPI_std)):\n",
    "        std_single = IPI_std[i].flatten()[:tmax]\n",
    "        STD[:,i] = std_single\n",
    "    \n",
    "    return STD\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirlst = glob.glob('SyncContData\\\\*_2_*ITIs.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_sync_cont_bias(ntrials, sigma, K, initI, alpha):\n",
    "    '''Simulate synchronization continuation and return the array of bias'''\n",
    "    durs = np.linspace(550, 817, 5)\n",
    "    meanITIs = []\n",
    "    stdITIs = []\n",
    "\n",
    "    for interval in durs:\n",
    "        usim, vsim, ysim, Ilst, siglst, u_p, v_p, y_p, I_p, production_lst = simulate_synchronization(ntrials=ntrials, \n",
    "                                                                                   durations=[interval] * 4 + [20000],  \n",
    "                                                                                   sigma=sigma, K=K, initI=initI, alpha=alpha)\n",
    "\n",
    "        # Find the IPI (inter-production interval)\n",
    "        ipi_lst = []\n",
    "        for i in range(production_lst.shape[1]):\n",
    "            single_production = production_lst[:,i]\n",
    "            #print(len(np.nonzero(single_production)[0]))\n",
    "            ipi_lst.append(np.diff(np.nonzero(single_production)[0])[1:21])\n",
    "        if np.array(ipi_lst).ndim != 2:\n",
    "            print('Warning: no production!')\n",
    "            return [np.array([]), np.array([]), np.array([]), np.array([])]\n",
    "        meanline = np.mean(np.array(ipi_lst), axis=0)\n",
    "        stdline = np.std(np.array(ipi_lst), axis=0)\n",
    "        meanITIs.append(meanline)\n",
    "        stdITIs.append(stdline)\n",
    "        \n",
    "    meanITIs = np.array(meanITIs) * 10\n",
    "    #print(meanITIs)\n",
    "    stdITIs = np.array(stdITIs) * 10\n",
    "    #print(stdITIs)\n",
    "    \n",
    "    bias_individual = meanITIs - durs[:,np.newaxis]\n",
    "    bias_all_sim = np.mean(bias_individual**2, axis=0)\n",
    "    std_all_sim = np.mean(stdITIs**2, axis=0)\n",
    "    \n",
    "    return np.sqrt(bias_all_sim), np.sqrt(std_all_sim), meanITIs, stdITIs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scipy.io.savemat('PlotTools/sync_cont_figure_021619.mat', {'bias_all_lst': bias_all_lst,\n",
    "#                                                          'bias_means': np.nanmean(bias_all_lst,axis=0),\n",
    "#                                                          'bias_sim': bias_sim_mean,\n",
    "#                                                          'Ival': Isummary,\n",
    "#                                                          'Kval': Ksummary,\n",
    "#                                                          'alphaval': alphasummary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit to individual subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_sync_cont_fitting(target, nsamples, niter, ntrials, sigma, Krange, Irange, alpha_range):\n",
    "    Klst = np.random.uniform(low=Krange[0], high=Krange[1], size=nsamples)\n",
    "    Ilst = np.random.uniform(low=Irange[0], high=Irange[1], size=nsamples)\n",
    "    alphalst = np.random.uniform(low=alpha_range[0], high=alpha_range[1], size=nsamples)\n",
    "    mselst = []\n",
    "    for i in range(nsamples):\n",
    "        K = Klst[i]\n",
    "        initI = Ilst[i]\n",
    "        alpha = alphalst[i]\n",
    "        bias_sim_mean, _, _, _ = simulate_sync_cont_bias(ntrials=ntrials, sigma=sigma, K=K, initI=initI, alpha=alpha)\n",
    "        if len(bias_sim_mean) == 0:\n",
    "            print('Bad trial')\n",
    "            continue\n",
    "        mse = np.sum((bias_sim_mean - target)**2)\n",
    "        print('    Iter %d: K = %.4f, I = %.4f, alpha = %.4f, mse = %.4f' % (i, K, initI, alpha, mse))\n",
    "        mselst.append(mse)\n",
    "    id = np.argmin(mselst)\n",
    "    return Ilst[id], Klst[id], alphalst[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 100\n",
    "Isummary = []\n",
    "Ksummary = []\n",
    "alphasummary = []\n",
    "\n",
    "for id in range(bias_all_lst.shape[0]):\n",
    "    print('Doing subject # %d of %d' % (id + 1, bias_all_lst.shape[0]))\n",
    "    target = bias_all_lst[id, :]\n",
    "    Ival, Kval, alphaval = do_sync_cont_fitting(target, nsamples, niter, ntrials=21, sigma=0.01, \n",
    "                                               Krange=[0.01, 5], Irange=[0.76, 0.78], alpha_range=[0.01, 0.1])\n",
    "    Isummary.append(Ival)\n",
    "    Ksummary.append(Kval)\n",
    "    alphasummary.append(alphaval)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data\n",
    "plotlst = [0,3,4,5,6,7]\n",
    "tmax = 20\n",
    "bias_all_lst = np.zeros((len(plotlst), tmax))\n",
    "color1 = 'slateblue'\n",
    "color2 = 'lightcoral'\n",
    "\n",
    "for id, i in enumerate(plotlst):\n",
    "    filename = dirlst[i]\n",
    "    print(filename)\n",
    "    bias_arr = find_bias_arr(filename, tmax)\n",
    "    bias = np.sqrt(np.nanmean(bias_arr**2, axis=1)) * 1000\n",
    "    \n",
    "    bias_all_lst[id,:] = bias\n",
    "    plt.plot(bias[:3], color1, alpha=0.5)\n",
    "    plt.plot(range(2,20), bias[2:], color2, alpha=0.5)\n",
    "    \n",
    "\n",
    "# Find individual subject fit\n",
    "Bias_sim_mean = []\n",
    "\n",
    "for id in range(len(Isummary)):\n",
    "    Ival = Isummary[id]\n",
    "    Kval = Ksummary[id]\n",
    "    alphaval = alphasummary[id]\n",
    "    bias_sim_mean, bias_sim_std, _, _ = simulate_sync_cont_bias(ntrials=1000, sigma=0.01, K=Kval, initI=Ival, alpha=alphaval)\n",
    "\n",
    "    plt.plot(np.nanmean(bias_all_lst,axis=0)[:3], color1, linewidth=3)\n",
    "    plt.plot(range(2,20), np.nanmean(bias_all_lst,axis=0)[2:], color2, linewidth=3)\n",
    "    plt.plot(bias_sim_mean, 'k--')\n",
    "    Bias_sim_mean.append(bias_sim_mean)\n",
    "plt.xlabel('Time step')\n",
    "plt.ylabel('Bias (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Bias_sim_mean = np.array(Bias_sim_mean)\n",
    "scipy.io.savemat('PlotTools/sync_cont_subject_fit_021619.mat', {'Bias_sim_mean': Bias_sim_mean, \n",
    "                                                            'bias_sim_mean': bias_sim_mean,\n",
    "                                                               'Isummary': Isummary,\n",
    "                                                               'Ksummary': Ksummary,\n",
    "                                                               'alphasummary': alphasummary})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_subject_ts_tp(filename):\n",
    "    bias_arr = find_bias_arr(filename, 20)\n",
    "    std_arr = find_std_arr(filename, 20)\n",
    "\n",
    "    # Plot ts-tp dependence (subject)\n",
    "    bias_first = bias_arr[0,:]\n",
    "    std_first = std_arr[0,:]\n",
    "    bias_third = bias_arr[2,:]\n",
    "    std_third = std_arr[2,:]\n",
    "    bias_fifth = bias_arr[4,:]\n",
    "    std_fifth = std_arr[4,:]\n",
    "\n",
    "    plt.errorbar(durs, durs + bias_third, std_third)\n",
    "    plt.errorbar(durs, durs + bias_fifth, std_fifth)\n",
    "    plt.plot(durs, durs, '--')\n",
    "    \n",
    "    \n",
    "def plot_model_ts_tp(Ival, Kval, alphaval, sigmaval):\n",
    "    _, _, meanITI, std_arr_sim = simulate_sync_cont_bias(ntrials=100, sigma=sigmaval, K=Kval, initI=Ival, alpha=alphaval)\n",
    "    \n",
    "    \n",
    "    # Plot ts-tp dependence (model)\n",
    "    bias_first_sim = meanITI[:,0]/1000 - durs\n",
    "    std_first_sim = std_arr_sim[:,0] / 1000\n",
    "    bias_third_sim = meanITI[:,2]/1000 - durs\n",
    "    std_third_sim = std_arr_sim[:,2] / 1000\n",
    "    bias_fifth_sim = meanITI[:,4]/1000 - durs\n",
    "    std_fifth_sim = std_arr_sim[:,4] / 1000\n",
    "\n",
    "    plt.errorbar(durs, durs + bias_third_sim, std_third_sim)\n",
    "    plt.errorbar(durs, durs + bias_fifth_sim, std_fifth_sim)\n",
    "    plt.plot(durs, durs, '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, meanITI, std_arr_sim = simulate_sync_cont_bias(ntrials=100, sigma=0.01, K=Ksummary[0], initI=Isummary[0],\n",
    "                                                     alpha=alphasummary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subject_ts_tp('C:\\\\Users\\\\Sur lab\\\\Dropbox (MIT)\\\\Jazayeri\\\\SyncContData\\\\AL_2_20170719_SynCon_ITIs.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_ts_tp(Ival=Isummary[0], Kval=Ksummary[0], alphaval=alphasummary[0], sigmaval=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "for i in range(6):\n",
    "    plt.subplot(6, 2, 2 * i + 1)\n",
    "    plot_subject_ts_tp(dirlst[plotlst[i]])\n",
    "    \n",
    "    plt.subplot(6, 2, 2 * i + 2)\n",
    "    plot_model_ts_tp(Ival=Isummary[i], Kval=Ksummary[i], alphaval=alphasummary[i], sigmaval=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we save results of subject/model ts-tp relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_ts_tp(Ival=0.5, Kval=0, alphaval=0, sigmaval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = []\n",
    "bias_arr_all = []\n",
    "std_arr_all = []\n",
    "meanITI_model = []\n",
    "stdITI_model = []\n",
    "\n",
    "for i in range(6):\n",
    "    # Subject info\n",
    "    filename = dirlst[plotlst[i]]\n",
    "    filenames.append(filename)\n",
    "\n",
    "    bias_arr = find_bias_arr(filename, 20)\n",
    "    std_arr = find_std_arr(filename, 20)\n",
    "    \n",
    "    bias_arr_all.append(bias_arr)\n",
    "    std_arr_all.append(std_arr)\n",
    "    \n",
    "    # Model info\n",
    "    _, _, meanITI, std_arr_sim = simulate_sync_cont_bias(ntrials=100, sigma=0.01, K=Ksummary[i], \n",
    "                                                         initI=Isummary[i], alpha=alphasummary[i])\n",
    "    meanITI_model.append(meanITI)\n",
    "    stdITI_model.append(std_arr_sim)\n",
    "    \n",
    "bias_arr_all = np.array(bias_arr_all)\n",
    "std_arr_all = np.array(std_arr_all)\n",
    "meanITI_model = np.array(meanITI_model)\n",
    "stdITI_model = np.array(stdITI_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.io.savemat('PlotTools/subject_ts_tp_sync_cont_021619.mat', {'filenames': filenames,\n",
    "                                                                 'bias_arr_all': bias_arr_all,\n",
    "                                                                 'std_arr_all': std_arr_all,\n",
    "                                                                 'durs': durs,\n",
    "                                                                 'meanITI_model': meanITI_model,\n",
    "                                                                 'stdITI_model': stdITI_model})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
