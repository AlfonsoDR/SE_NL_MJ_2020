{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete updating algorithm\n",
    "\n",
    "### Continuous time definitions\n",
    "$y_{\\textrm{ref}}$ : Reference level\n",
    "\n",
    "$y_{\\textrm{SAM}}$ : Output of SAM\n",
    "\n",
    "$y_{\\textrm{MPM}}$ : Output of of MPM\n",
    "\n",
    "$I_{\\textrm{SAM}}$ : Input to SAM\n",
    "\n",
    "$I_{\\textrm{MPM}}$ : Input to MPM\n",
    "\n",
    "\n",
    "### Translation into discrete time\n",
    "$i$ will index *time-points* and *intervals*\n",
    "\n",
    "$t_p^i$ : time of $i$th production\n",
    "\n",
    "$t_s^i$ : time of $i$th stimulus\n",
    "\n",
    "$\\textrm{ISI}^i$ = $t_s^{i+1} - t_s^i$\n",
    "\n",
    "$\\textrm{IPI}^i$ = $t_p^{i+1} - t_p^i$\n",
    "\n",
    "$y_{\\textrm{SAM}}^i=I_{\\textrm{SAM}}^i*\\textrm{ISI}^i$\n",
    "\n",
    "$I_{\\textrm{SAM}}^{i+1}=I_{\\textrm{SAM}}^i+\\beta(y_{\\textrm{ref}}-y_{\\textrm{SAM}}^i)$\n",
    "\n",
    "$I_{\\textrm{MPM}}^{i+1} = I_{\\textrm{SAM}}^{i+1} + \\alpha(y_{\\textrm{out}}^i-y_{\\textrm{MPM}}^i)$\n",
    "\n",
    "$\\textrm{IPI}^i=y_{\\textrm{ref}}/I_{\\textrm{MPM}}$\n",
    "\n",
    "$t_p^{i+1}=t_p^i+\\textrm{IPI}^i$\n",
    "\n",
    "By definition $y_{\\textrm{MPM}}^i=y_{\\textrm{ref}}$ (output of $y_{\\textrm{MPM}}$ at ith production)\n",
    "\n",
    "The value of $y_{\\textrm{out}}^i$ represents the output of the SAM at the time of the $i$th production. During synchronization that will be:\n",
    "\n",
    "$y_{\\textrm{out}}^i = I_{\\textrm{SAM}}^i*(t_p^i-t_s^{i-1})$\n",
    "\n",
    "During continuation:\n",
    "\n",
    "$y_{\\textrm{out}}^i = y_{\\textrm{SAM}}^\\infty$\n",
    "\n",
    "with $y_{\\textrm{SAM}}^\\infty$ representing the terminal output of the SAM module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definitions\n",
    "def I_s_update(I_s_in,beta,y_ref,y_s):\n",
    "    I_s_out = I_s_in + beta*(y_ref - y_s)\n",
    "    \n",
    "    return I_s_out\n",
    "\n",
    "def I_p_update(I_s,alpha,y_p,y_out):\n",
    "    I_p_out = I_s + alpha*(y_out-y_p)\n",
    "    \n",
    "    return I_p_out\n",
    "\n",
    "def discreteAlgorithm_multiple(ISI, n, beta=0.5, alpha=0.1, y_ref=1, \n",
    "                               I_s_init=0.8, y_s_infty=1.5, sigma=0):\n",
    "    '''Perform multiple simulations of the discrete algorithm\n",
    "    Returns: an array of size n x T'''\n",
    "    IPIs = []\n",
    "    for i in range(n):\n",
    "        _, t_p, IPI, _, _, _ = discreteAlgorithm(ISI, beta, alpha, y_ref, I_s_init,\n",
    "                                                        y_s_infty, sigma)\n",
    "        #print('tp and IPI')\n",
    "        #print(t_p)\n",
    "        #print(IPI)\n",
    "        #print(np.diff(t_p))\n",
    "        IPI_noise = np.diff(t_p)\n",
    "        IPIs.append(IPI_noise)\n",
    "        \n",
    "    return np.array(IPIs)\n",
    "    \n",
    "\n",
    "\n",
    "def discreteAlgorithm(ISI, beta=0.5, alpha=0.1, y_ref=1, I_s_init=0.8, y_s_infty=1.5, sigma=0):\n",
    "\n",
    "    t_s = np.zeros(len(ISI)+1)\n",
    "    t_s[1:len(ISI)+1] = np.cumsum(ISI)\n",
    "    IPI = np.zeros((len(t_s))-1)\n",
    "    t_p = np.zeros((len(t_s)))\n",
    "    I_s = np.zeros((len(t_s)))\n",
    "    I_p = np.zeros((len(t_s)))\n",
    "    y_s = np.zeros((len(t_s)))\n",
    "    I_p[0] = I_s_init\n",
    "    I_s[0] = I_s_init\n",
    "\n",
    "    for i in range(len(ISI)):\n",
    "        \n",
    "        IPI[i] = y_ref/I_p[i]\n",
    "        if i > 0:\n",
    "            noise = np.random.randn() * sigma\n",
    "            \n",
    "            t_p[i+1] = t_p[i] + IPI[i] + noise\n",
    "            #print(t_p)\n",
    "            #print(IPI)\n",
    "        else:\n",
    "            #print(i, 'here2')\n",
    "            t_p[i+1] = IPI[i] + np.random.randn() * sigma\n",
    "        \n",
    "        if np.isnan(ISI[i]):\n",
    "            y_s[i] = y_s_infty\n",
    "            I_s[i+1] = I_s[i]\n",
    "        else:\n",
    "            y_s[i] = I_s[i]*ISI[i]\n",
    "            I_s[i+1] = I_s_update(I_s[i],beta,y_ref,y_s[i])\n",
    "\n",
    "        \n",
    "        if np.isnan(ISI[i]):\n",
    "            y_out = y_s_infty\n",
    "        else:\n",
    "            if i == 0:\n",
    "                y_out = y_ref\n",
    "            else:\n",
    "                y_out = I_s[i]*(t_p[i]-t_s[i-1])\n",
    "            #print(i,y_out)\n",
    "\n",
    "        # Standard code for algorithm, implementing integration of differences over time\n",
    "        I_p[i+1] = I_p_update(I_s[i+1],alpha,y_ref,y_out)\n",
    "        \n",
    "        # Code that does not integrate differences over time\n",
    "        #if np.isnan(t_s[i]):\n",
    "        #    I_p[i+1] = I_p_update(I_s[i+1],alpha,t_p[i],t_p[i]+0.4)\n",
    "        #else:       \n",
    "        #    I_p[i+1] = I_p_update(I_s[i+1],alpha,t_p[i],t_s[i])\n",
    "        \n",
    "        #print(t_s[i],t_p[i],IPI[i])\n",
    "    #print(t_p)\n",
    "    return t_s, t_p, IPI, I_s, I_p, y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discreteAlgorithm_multiple([0.5] * 4 + [np.nan] * 7, 3, sigma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronization to a constant ISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple synchronization\n",
    "ISI = [0.4] * 500\n",
    "t_s, t_p, IPI, I_s, I_p, y_s = discreteAlgorithm(ISI, beta=0.2, alpha=0.1, y_ref=1, I_s_init=1/0.35, sigma=0)\n",
    "\n",
    "#for i in range(len(t_s)):\n",
    "#    print(t_s[i],t_p[i],IPI[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ISI)\n",
    "plt.plot(IPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_p-t_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step change\n",
    "ISI = np.concatenate((0.80*np.ones(100),1.00*np.ones(30)))\n",
    "del t_p\n",
    "del t_s\n",
    "del IPI\n",
    "del I_s\n",
    "del I_p\n",
    "del y_s\n",
    "t_s, t_p, IPI, I_s, I_p, y_s = discreteAlgorithm(ISI, beta=0.5, alpha=0.1, y_ref=1, I_s_init=1/0.8, sigma=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ISI)\n",
    "plt.plot(IPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_p-t_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISI = np.concatenate((0.80*np.ones(4),1.00*np.ones(9)))\n",
    "betas = [0.5,0.7,0.9]\n",
    "alpha = 0.3\n",
    "TS = np.zeros((14,len(betas)))\n",
    "TP = np.zeros((14,len(betas)))\n",
    "IPIs = np.zeros((13,len(betas)))\n",
    "for betai in range(len(betas)):\n",
    "    t_s, t_p, IPI, I_s, I_p, y_s = discreteAlgorithm(ISI, beta=betas[betai], alpha=alpha, y_ref=1, I_s_init=1/0.8)\n",
    "    TS[:,betai] = t_s\n",
    "    TP[:,betai] = t_p\n",
    "    IPIs[:,betai] = IPI\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ISI,IPIs[0:-1,0])\n",
    "plt.plot(ISI)\n",
    "plt.plot(IPIs[0:-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(TP-TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Phase shift\n",
    "ISI = np.concatenate((0.80*np.ones(50),0.9*np.ones(1),0.80*np.ones(50)))\n",
    "del t_p\n",
    "del t_s\n",
    "del IPI\n",
    "del I_s\n",
    "del I_p\n",
    "del y_s\n",
    "t_s, t_p, IPI, I_s, I_p, y_s = discreteAlgorithm(ISI, beta=0.7, alpha=0.1, y_ref=1, I_s_init=1/0.8, sigma=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ISI)\n",
    "plt.plot(IPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_p-t_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISI = np.concatenate((0.80*np.ones(4),0.9*np.ones(1),0.80*np.ones(8)))\n",
    "beta = 0.7\n",
    "alphas = [0.1,0.2,0.3]\n",
    "TS = np.zeros((14,len(betas)))\n",
    "TP = np.zeros((14,len(betas)))\n",
    "IPIs = np.zeros((13,len(betas)))\n",
    "for alphai in range(len(alphas)):\n",
    "    t_s, t_p, IPI, I_s, I_p, y_s = discreteAlgorithm(ISI, beta=beta, alpha=alphas[alphai], y_ref=1, I_s_init=1/0.8)\n",
    "    TS[:,alphai] = t_s\n",
    "    TP[:,alphai] = t_p\n",
    "    IPIs[:,alphai] = IPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ISI)\n",
    "plt.plot(IPIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(TP-TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimulus jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stimulus jitter\n",
    "ISI = np.concatenate((0.80*np.ones(50),0.9*np.ones(1), 0.7*np.ones(1), 0.80*np.ones(49)))\n",
    "del t_p\n",
    "del t_s\n",
    "del IPI\n",
    "del I_s\n",
    "del I_p\n",
    "del y_s\n",
    "t_s, t_p, IPI, I_s, I_p, y_s = discreteAlgorithm(ISI, beta=0.7, alpha=0.1, y_ref=1, I_s_init=1/0.8, sigma=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ISI)\n",
    "plt.plot(IPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_p-t_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISI = np.concatenate((0.80*np.ones(4),0.9*np.ones(1), 0.7*np.ones(1), 0.80*np.ones(7)))\n",
    "beta = 0.7\n",
    "alphas = [0.1,0.2,0.3]\n",
    "TS = np.zeros((14,len(betas)))\n",
    "TP = np.zeros((14,len(betas)))\n",
    "IPIs = np.zeros((13,len(betas)))\n",
    "for alphai in range(len(alphas)):\n",
    "    t_s, t_p, IPI, I_s, I_p, y_s = discreteAlgorithm(ISI, beta=beta, alpha=alphas[alphai], y_ref=1, I_s_init=1/0.8)\n",
    "    TS[:,alphai] = t_s\n",
    "    TP[:,alphai] = t_p\n",
    "    IPIs[:,alphai] = IPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ISI)\n",
    "plt.plot(IPIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(TP-TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2-Go, 1-2-3-Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_123Go(nstages=3,beta=0.75,alpha=0.0,ISI0=0.8,y_ref=1,ISImin=0.600,\n",
    "                   ISImax=1.000,number=5, sigma=0):\n",
    "    # 1-2-Go, 1-2-3-Go\n",
    "    ISIs = np.linspace(ISImin,ISImax,num=number)\n",
    "    ISI_list = np.nan*np.ones((len(ISIs),nstages))\n",
    "    IPI_list = np.nan*np.ones((len(ISIs),nstages))\n",
    "    t_s_list = []\n",
    "    t_p_list = []\n",
    "    for i in range(len(ISIs)):\n",
    "        ISI_list[i,:] = ISIs[i]*np.ones(nstages)\n",
    "        ISI = ISI_list[i,:]\n",
    "        t_s, t_p, IPI, I_s, I_p, y_s = discreteAlgorithm(ISI, beta=beta, alpha=alpha, \n",
    "                                                         y_ref=y_ref, I_s_init=1/ISI0,\n",
    "                                                        sigma=sigma)\n",
    "\n",
    "        t_s_list.append(t_s)\n",
    "        t_p_list.append(t_p)\n",
    "        IPI_list[i,:] = IPI\n",
    "    \n",
    "    return IPI_list, ISIs\n",
    "\n",
    "\n",
    "def simulate_123Go_noise(nstages=3,beta=0.75,alpha=0.0,ISI0=0.8,y_ref=1,ISImin=0.600,\n",
    "                   ISImax=1.000,number=5, sigma=0, ntrials=100):\n",
    "    # 1-2-Go, 1-2-3-Go\n",
    "    ISIs = np.linspace(ISImin,ISImax,num=number)\n",
    "    meanIPIs = []\n",
    "    stdIPIs = []\n",
    "    \n",
    "    for i in range(len(ISIs)): \n",
    "        ISI = ISIs[i]*np.ones(nstages)\n",
    "        IPIs = discreteAlgorithm_multiple(ISI, ntrials,\n",
    "                                    beta=beta, alpha=alpha, \n",
    "                                    y_ref=y_ref, I_s_init=1/ISI0,\n",
    "                                    sigma=sigma)[:,-1]\n",
    "        meanIPIs.append(np.mean(IPIs))\n",
    "        stdIPIs.append(np.std(IPIs))\n",
    "\n",
    "    \n",
    "    return np.array(meanIPIs), np.array(stdIPIs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(IPI_list.shape)\n",
    "tempISIs = np.matlib.repmat(ISIs,3,1)\n",
    "sqErrs = np.square(IPI_list - np.transpose(tempISIs))\n",
    "sqBIAS = sqErrs.sum(axis=0)/len(ISIs)\n",
    "print(sqBIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.plot(sqBIAS[1:3])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(np.transpose(tempISIs),IPI_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronization/continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronization/continuation\n",
    "ISIs = np.linspace(0.550,0.817,num=5)\n",
    "print(ISIs)\n",
    "ISI_list = np.nan*np.ones((len(ISIs),12))\n",
    "IPI_list = np.nan*np.ones((len(ISIs),12))\n",
    "t_s_list = []\n",
    "t_p_list = []\n",
    "for i in range(len(ISIs)):\n",
    "    ISI_list[i,:] = np.concatenate((ISIs[i]*np.ones(4),np.nan*np.ones(8)))\n",
    "    del t_p\n",
    "    del t_s\n",
    "    del IPI\n",
    "    del I_s\n",
    "    del I_p\n",
    "    del y_s\n",
    "    ISI = ISI_list[i,:]\n",
    "    t_s, t_p, IPI, I_s, I_p, y_s = discreteAlgorithm(ISI, beta=0.75, alpha=0.1, y_ref=1, \n",
    "                                                     I_s_init=1/0.6835, y_s_infty=1.5,\n",
    "                                                    sigma=0)\n",
    "    \n",
    "    t_s_list.append(t_s)\n",
    "    t_p_list.append(t_p)\n",
    "    IPI_list[i,:] = IPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ISI)\n",
    "plt.plot(IPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_p-t_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempISIs = np.matlib.repmat(ISIs,12,1)\n",
    "sqErrs = np.square(IPI_list - np.transpose(tempISIs))\n",
    "sqBIAS = sqErrs.sum(axis=0)/len(ISIs)\n",
    "print(sqBIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.plot(sqBIAS[1:12])\n",
    "\n",
    "plt.subplot(122)\n",
    "print(tempISIs.shape)\n",
    "plt.plot(np.transpose(tempISIs[(0,4,10),:]),IPI_list[:,(0,4,10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fit to behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronization/continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import glob\n",
    "\n",
    "def find_bias_arr(filename, tmax):\n",
    "    '''filename: SynCon_ITIs file name\n",
    "    tmax: max number of taps to consider\n",
    "    \n",
    "    Returns: the bias array, tmax x number of intervals in prior'''\n",
    "    data = scipy.io.loadmat(filename)\n",
    "    durs = data['durs'].flatten()\n",
    "    splits = data['allDur_splits']\n",
    "    IPI_mean = data['allDur_mean'][0]\n",
    "    \n",
    "    Bias = np.zeros((tmax, 5))\n",
    "\n",
    "    for i in range(len(IPI_mean)):\n",
    "        IPI_single = IPI_mean[i].flatten()[:tmax]\n",
    "        bias_single = IPI_single - durs[i]\n",
    "        Bias[:,i] = bias_single\n",
    "    \n",
    "    return Bias\n",
    "\n",
    "def plot_subject_ts_tp(filename):\n",
    "    bias_arr = find_bias_arr(filename, 20)\n",
    "    std_arr = find_std_arr(filename, 20)\n",
    "    data = scipy.io.loadmat(filename)\n",
    "    durs = data['durs'].flatten()\n",
    "\n",
    "    # Plot ts-tp dependence (subject)\n",
    "    bias_first = bias_arr[0,:]\n",
    "    std_first = std_arr[0,:]\n",
    "    bias_third = bias_arr[2,:]\n",
    "    std_third = std_arr[2,:]\n",
    "    bias_fifth = bias_arr[4,:]\n",
    "    std_fifth = std_arr[4,:]\n",
    "\n",
    "    plt.errorbar(durs, durs + bias_third, std_third)\n",
    "    plt.errorbar(durs, durs + bias_fifth, std_fifth)\n",
    "    plt.plot(durs, durs, '--')\n",
    "\n",
    "def find_std_arr(filename, tmax):\n",
    "    '''filename: SynCon_ITIs file name\n",
    "    tmax: max number of taps to consider\n",
    "    \n",
    "    Returns: the bias array, tmax x number of intervals in prior'''\n",
    "    data = scipy.io.loadmat(filename)\n",
    "    durs = data['durs'].flatten()\n",
    "    splits = data['allDur_splits']\n",
    "    IPI_std = data['allDur_std'][0]\n",
    "    \n",
    "    STD = np.zeros((tmax, 5))\n",
    "\n",
    "    for i in range(len(IPI_std)):\n",
    "        std_single = IPI_std[i].flatten()[:tmax]\n",
    "        STD[:,i] = std_single\n",
    "    \n",
    "    return STD\n",
    "    \n",
    "def simulate_sync_cont_bias(ISIs, ntrials, beta, alpha, ISI0, sigma):\n",
    "    meanITIs = []\n",
    "\n",
    "    for i in range(len(ISIs)):\n",
    "        ISI_list = np.concatenate((ISIs[i]*np.ones(4),np.nan*np.ones(17)))        \n",
    "        IPI_lst = discreteAlgorithm_multiple(ISI_list, ntrials, beta, alpha, y_ref=1, \n",
    "                               I_s_init=ISI0, y_s_infty=1.5, sigma=sigma)\n",
    "        #print(IPI_lst)\n",
    "        meanIPI = np.mean(IPI_lst, axis=0)\n",
    "        meanITIs.append(meanIPI)\n",
    "        \n",
    "    meanITIs = np.array(meanITIs)\n",
    "    bias_individual = meanITIs - ISIs[:,np.newaxis]\n",
    "    bias_all_sim = np.mean(bias_individual**2, axis=0)\n",
    "    return np.sqrt(bias_all_sim)[1:]\n",
    "\n",
    "def minimizer_noise(filename,ISIs,nsamples,betaRange,alphaRange,ISI0Range,sigma):\n",
    "    bias_arr = find_bias_arr(filename, 20)\n",
    "    betas = np.random.uniform(low=betaRange[0], high=betaRange[1], size=nsamples)\n",
    "    alphas = np.random.uniform(low=alphaRange[0], high=alphaRange[1], size=nsamples)\n",
    "    ISI0s = np.random.uniform(low=ISI0Range[0], high=ISI0Range[1], size=nsamples)\n",
    "    mse = np.nan*np.ones((nsamples,1))\n",
    "    \n",
    "    ntrials = 21\n",
    "    for j in range(nsamples):\n",
    "        biasSim = simulate_sync_cont_bias(ISIs, ntrials, betas[j], \n",
    "                                          alphas[j], 1/ISI0s[j], sigma)\n",
    "        biasObs = np.sqrt( np.nanmean(bias_arr**2,axis=1) )\n",
    "        mse[j] = np.nanmean((biasObs - biasSim)**2)\n",
    "        \n",
    "    id = np.argmin(mse)\n",
    "    print(id)\n",
    "    beta = betas[id]\n",
    "    alpha = alphas[id]\n",
    "    ISI0 = ISI0s[id]\n",
    "    return beta, alpha, ISI0\n",
    "\n",
    "def minimizer(filename,ISIs,nsamples,betaRange,alphaRange,ISI0Range):\n",
    "    bias_arr = find_bias_arr(filename, 20)\n",
    "    \n",
    "    betas = np.random.uniform(low=betaRange[0], high=betaRange[1], size=nsamples)\n",
    "    alphas = np.random.uniform(low=alphaRange[0], high=alphaRange[1], size=nsamples)\n",
    "    ISI0s = np.random.uniform(low=ISI0Range[0], high=ISI0Range[1], size=nsamples)\n",
    "    mse = np.nan*np.ones((nsamples,1))\n",
    "    for j in range(nsamples):\n",
    "        ISI_list = np.nan*np.ones((len(ISIs),21))\n",
    "        ISI_list2 = np.nan*np.ones((len(ISIs),21))\n",
    "        IPI_list = np.nan*np.ones((len(ISIs),21))\n",
    "        t_s_list = []\n",
    "        t_p_list = []\n",
    "        for i in range(len(ISIs)):\n",
    "            ISI_list[i,:] = np.concatenate((ISIs[i]*np.ones(4),np.nan*np.ones(17)))\n",
    "            ISI_list2[i,:] = ISIs[i]*np.ones(21)\n",
    "            ISI = ISI_list[i,:]\n",
    "            _, _, IPI, _, _, _ = discreteAlgorithm(ISI, beta=betas[j], alpha=alphas[j], y_ref=1,\n",
    "                                                             I_s_init=1/ISI0s[j], y_s_infty=1.5, sigma=0)\n",
    "            IPI_list[i,:] = IPI\n",
    "            \n",
    "        biasSim = np.sqrt( np.nanmean((IPI_list[:,1:]-ISI_list2[:,1:])**2,axis=0) )\n",
    "        biasObs = np.sqrt( np.nanmean(bias_arr**2,axis=1) )\n",
    "        mse[j] = np.nanmean((biasObs - biasSim)**2)\n",
    "           \n",
    "    id = np.argmin(mse)\n",
    "    print(id)\n",
    "    beta = betas[id]\n",
    "    alpha = alphas[id]\n",
    "    ISI0 = ISI0s[id]\n",
    "    return beta, alpha, ISI0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISIs = np.linspace(0.550,0.817,num=5)\n",
    "dirlst = glob.glob('C:\\\\Users\\\\Le\\\\Dropbox (MIT)\\\\Jazayeri\\\\SyncContData\\\\*_2_*ITIs.mat')\n",
    "#dirlst = glob.glob('/Users/swe/Dropbox (MIT)/CircuitModel/Data/*_2_*ITIs.mat')\n",
    "filename = dirlst[4] #'/Users/swe/Dropbox (MIT)/CircuitModel/Data/FK_2_20170721_SynCon_ITIs.mat'\n",
    "print(filename)\n",
    "beta, alpha, ISI0 = minimizer(filename, ISIs,nsamples=1000, betaRange=[0,0.8], alphaRange=[0,0.8], ISI0Range=[0.5,0.9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BETAS = np.zeros((len(dirlst),1))\n",
    "ALPHAS = np.zeros((len(dirlst),1))\n",
    "ISIinits = np.zeros((len(dirlst),1))\n",
    "for filei in range(len(dirlst)):\n",
    "    filename = dirlst[filei] #'/Users/swe/Dropbox (MIT)/CircuitModel/Data/FK_2_20170721_SynCon_ITIs.mat'\n",
    "    print(filename)\n",
    "    beta, alpha, ISI0 = minimizer_noise(filename, ISIs,nsamples=1000, \n",
    "                                        betaRange=[0,0.8], alphaRange=[0,0.8], \n",
    "                                        ISI0Range=[0.5,0.9], sigma=0.06)\n",
    "    \n",
    "    BETAS[filei] = beta\n",
    "    ALPHAS[filei] = alpha\n",
    "    ISIinits[filei] = ISI0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the fitted values, we now perform the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlst = [0,3,4,5,6,7]\n",
    "\n",
    "Bias_sim_mean = np.zeros((6, 20))\n",
    "\n",
    "\n",
    "\n",
    "for idx, filei in enumerate(plotlst):\n",
    "    # Perform the simulation\n",
    "    ISI_list = np.nan*np.ones((len(ISIs),21))\n",
    "    IPI_list = np.nan*np.ones((len(ISIs),21))\n",
    "    t_s_list = []\n",
    "    t_p_list = []\n",
    "    \n",
    "    beta = BETAS[filei, 0]\n",
    "    alpha = ALPHAS[filei, 0]\n",
    "    ISI0 = ISIinits[filei, 0]\n",
    "    filename = dirlst[filei]\n",
    "\n",
    "\n",
    "    bias_arr = find_bias_arr(filename, 20)\n",
    "    biasObs = np.sqrt(np.nanmean(bias_arr**2,axis=1))\n",
    "\n",
    "\n",
    "    biasModel = simulate_sync_cont_bias(ISIs, ntrials=21, beta=beta, \n",
    "                                        alpha=alpha, ISI0=1/ISI0, sigma=0.06)\n",
    "    plt.subplot(121)\n",
    "    plt.plot(biasModel)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(biasObs)\n",
    "\n",
    "    Bias_sim_mean[idx, :] = biasModel * 1000\n",
    "    #plt.plot(np.transpose(tempISIs[(3,5),:]),IPI_list[:,(3,5)])\n",
    "    #plot_subject_ts_tp(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scipy.io.savemat('PlotTools/sync_cont_figure_algorithmic_circuit_012120c.mat', {'alphasummary': ALPHAS,\n",
    "#                                                             'Isummary': ISIinits,\n",
    "#                                                             'Ksummary': BETAS,\n",
    "#                                                             'Bias_sim_mean': Bias_sim_mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For figure 8b & 8c\n",
    "plotlst = [0,3,4,5,6,7]\n",
    "\n",
    "meanITI_model = []\n",
    "stdITI_model = []\n",
    "\n",
    "ntrials = 21\n",
    "\n",
    "for idx, filei in enumerate(plotlst):\n",
    "    # Perform the simulation\n",
    "    beta = BETAS[filei, 0]\n",
    "    alpha = ALPHAS[filei, 0]\n",
    "    ISI0 = ISIinits[filei, 0]\n",
    "    filename = dirlst[filei]\n",
    "    sigma = 0.06\n",
    "    \n",
    "    meanITIs = []\n",
    "    stdITIs = []\n",
    "\n",
    "    for i in range(len(ISIs)):\n",
    "        ISI_list = np.concatenate((ISIs[i]*np.ones(4),np.nan*np.ones(17)))        \n",
    "        IPI_lst = discreteAlgorithm_multiple(ISI_list, ntrials, beta, alpha, y_ref=1, \n",
    "                               I_s_init=1/ISI0, y_s_infty=1.5, sigma=sigma)\n",
    "        #print(IPI_lst)\n",
    "        meanIPI = np.mean(IPI_lst, axis=0)\n",
    "        stdIPI = np.std(IPI_lst, axis=0)\n",
    "        meanITIs.append(meanIPI)\n",
    "        stdITIs.append(stdIPI)\n",
    "        \n",
    "    meanITI_model.append(np.array(meanITIs)[:,1:] * 1000)\n",
    "    stdITI_model.append(np.array(stdITIs)[:,1:] * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scipy.io.savemat('PlotTools/subject_ts_tp_sync_cont_discreteAlgo_012220.mat',\n",
    "#                {'durs': ISIs, 'meanITI_model': meanITI_model, \n",
    "#                 'stdITI_model': stdITI_model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2-Go/1-2-3-Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_time_lst(nstages, beta, alpha, ISI0):\n",
    "    '''Simulate and return the array of times of threshold crossing'''\n",
    "    IPI_list, ISIs = simulate_123Go(nstages=nstages,beta=beta,alpha=alpha,ISI0=ISI0)\n",
    "    times = 1000*IPI_list[:,-1]\n",
    "\n",
    "    return times\n",
    "    \n",
    "\n",
    "def do_beta_alpha_ISI0_fitting(subject_file, nsamples, ntrials, betalow, betahigh, \n",
    "                               alphalow, alphahigh, ISI0low, ISI0high, sigma):\n",
    "    '''Inputs:\n",
    "    - subject_file: .mat file with the behavioral results of the subject\n",
    "    - nsamples: number of random (beta,alpha,ISI0) combinations to sample\n",
    "    - betalow, betahigh, alphalow, alphahigh, ISI0low, ISI0high: ranges of beta, alpha, and ISI0 for sampling\n",
    "    \n",
    "    Outputs:\n",
    "    beta, alpha, ISI0: the optimal combination to minimize the mse between the mean simulated times\n",
    "    and the mean behavioral times of the subject'''\n",
    "    #print('sigmaval = ', sigmaval)\n",
    "    betalst = np.random.uniform(low=betalow, high=betahigh, size=nsamples)\n",
    "    alphalst = np.random.uniform(low=alphalow, high=alphahigh, size=nsamples)\n",
    "    ISI0lst = np.random.uniform(low=ISI0low, high=ISI0high, size=nsamples)\n",
    "\n",
    "    # Load data for subject SWE(RSG/RSSG, Seth provided)\n",
    "    swedata = scipy.io.loadmat(subject_file)\n",
    "    mtp_in = swedata['mtp_in']\n",
    "    stdtp_in = swedata['stdtp_in']\n",
    "\n",
    "    target_time1 = mtp_in[:,0]\n",
    "    target_time2 = mtp_in[:,1]\n",
    "\n",
    "    errorlst = []\n",
    "\n",
    "    for k in range(nsamples):\n",
    "        ISI0val = ISI0lst[k]\n",
    "        betaval = betalst[k]\n",
    "        alphaval = alphalst[k]\n",
    "\n",
    "        #1,2,Go simulation\n",
    "        prod_time_lst, _ = simulate_123Go_noise(nstages=2, ntrials=ntrials,\n",
    "                                    beta=betaval, alpha=alphaval, ISI0=ISI0val,\n",
    "                                               sigma=sigma)\n",
    "\n",
    "        #1,2,3,Go simulation\n",
    "        prod_time_lst2, _ = simulate_123Go_noise(nstages=3, ntrials=ntrials,\n",
    "                                    beta=betaval, alpha=alphaval, ISI0=ISI0val,\n",
    "                                                sigma=sigma)\n",
    "\n",
    "        # Continue if there is a nan   \n",
    "        error1 = (np.transpose(prod_time_lst) * 1000 - target_time1) ** 2\n",
    "        error2 = (np.transpose(prod_time_lst2) * 1000 - target_time2) ** 2\n",
    "        \n",
    "        if np.sum(np.isnan(error1)) + np.sum(np.isnan(error2)) > 0:\n",
    "            error = np.inf\n",
    "            print('nan encountered')\n",
    "        else:\n",
    "        # Error function to minimize\n",
    "            error = np.sum(error1) + np.sum(error2)\n",
    "        errorlst.append(error)\n",
    "\n",
    "\n",
    "    idx = np.argmin(errorlst)\n",
    "    #print(errorlst)\n",
    "    return betalst[idx], alphalst[idx], ISI0lst[idx]\n",
    "\n",
    "\n",
    "def do_sigma_fitting(subject_file, nsamples, ntrials, sigmalow, sigmahigh, \n",
    "                               beta, alpha, ISI0):\n",
    "    '''Inputs:\n",
    "    - subject_file: .mat file with the behavioral results of the subject\n",
    "    - nsamples: number of random (beta,alpha,ISI0) combinations to sample\n",
    "    - sigmalow, sigmahigh: ranges of sigma for sampling\n",
    "    \n",
    "    Outputs:\n",
    "    sigma: the optimal sigma value to minimize the mse between the std simulated times\n",
    "    and the mean behavioral times of the subject'''\n",
    "    sigmalst = np.linspace(sigmalow, sigmahigh, nsamples)\n",
    "\n",
    "    # Load data for subject SWE(RSG/RSSG, Seth provided)\n",
    "    swedata = scipy.io.loadmat(subject_file)\n",
    "    mtp_in = swedata['mtp_in']\n",
    "    stdtp_in = swedata['stdtp_in']\n",
    "\n",
    "    target_std1 = stdtp_in[:,0]\n",
    "    target_std2 = stdtp_in[:,1]\n",
    "\n",
    "    errorlst = []\n",
    "\n",
    "    for k in range(nsamples):\n",
    "        sigmaval = sigmalst[k]\n",
    "\n",
    "        #1,2,Go simulation\n",
    "        _, prod_std_lst = simulate_123Go_noise(nstages=2, ntrials=ntrials,\n",
    "                                    beta=beta, alpha=alpha, ISI0=ISI0, sigma=sigmaval)\n",
    "\n",
    "        #1,2,3,Go simulation\n",
    "        _, prod_std_lst2 = simulate_123Go_noise(nstages=3, ntrials=ntrials,\n",
    "                                    beta=beta, alpha=alpha, ISI0=ISI0, sigma=sigmaval)\n",
    "\n",
    "        # Continue if there is a nan   \n",
    "        error1 = (np.transpose(prod_std_lst) * 1000 - target_std1) ** 2\n",
    "        error2 = (np.transpose(prod_std_lst2) * 1000 - target_std2) ** 2\n",
    "        \n",
    "        if np.sum(np.isnan(error1)) + np.sum(np.isnan(error2)) > 0:\n",
    "            error = np.inf\n",
    "            print('nan encountered')\n",
    "        else:\n",
    "        # Error function to minimize\n",
    "            error = np.sum(error1) + np.sum(error2)\n",
    "        errorlst.append(error)\n",
    "\n",
    "\n",
    "    idx = np.argmin(errorlst)\n",
    "    #print(errorlst)\n",
    "    return sigmalst[idx]\n",
    "\n",
    "def subject_fitting(subject_file, nsamples, nsamples2, ntrials,\n",
    "                    betalow, betahigh, alphalow, alphahigh, ISI0low, ISI0high,\n",
    "                    sigmalow, sigmahigh, niter=5, sigma_init=0):\n",
    "    '''Performs fitting of sigma, I, K for a given subject file,\n",
    "    Inputs:\n",
    "    - subject_file: name of .mat behavior file,\n",
    "    - nsamples: number of I-K combinations to sample\n",
    "    - nsamples2: number of sigma values to sample\n",
    "    - ntrials: number of trials for averaging\n",
    "    - Klow, Khigh, Ilow, Ihigh, sigmalow, sigmahigh: specify the range of K, I and sigma\n",
    "    - print_every: to print a line every x combinations\n",
    "    - niter: how many times to alternate between IK sampling and sigma sampling\n",
    "    - sigma_init: initial value of sigma\n",
    "    Returns the fitted combination (sigma, I, K)'''\n",
    "    sigmaval = sigma_init\n",
    "    for i in range(niter):\n",
    "        print('Iteration #', i)\n",
    "        beta, alpha, ISI0 = do_beta_alpha_ISI0_fitting(subject_file, nsamples=nsamples, \n",
    "                                                       ntrials=ntrials,\n",
    "                                               betalow=betalow, betahigh=betahigh, \n",
    "                                               alphalow=alphalow, alphahigh=alphahigh, \n",
    "                                               ISI0low=ISI0low, ISI0high=ISI0high,\n",
    "                                              sigma=sigmaval)\n",
    "\n",
    "        sigmaval = do_sigma_fitting(subject_file, nsamples=nsamples2, ntrials=ntrials,\n",
    "                        sigmalow=sigmalow, sigmahigh=sigmahigh, \n",
    "                                 beta=beta, alpha=alpha, ISI0=ISI0)\n",
    "        \n",
    "    # One last round of IK fitting\n",
    "    beta, alpha, ISI0 = do_beta_alpha_ISI0_fitting(subject_file, nsamples=nsamples, \n",
    "                                                       ntrials=ntrials,\n",
    "                                               betalow=betalow, betahigh=betahigh, \n",
    "                                               alphalow=alphalow, alphahigh=alphahigh, \n",
    "                                               ISI0low=ISI0low, ISI0high=ISI0high,\n",
    "                                              sigma=sigmaval)\n",
    "    return beta, alpha, ISI0, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirlst = glob.glob('C:/Users/Le/Dropbox (MIT)/Jazayeri/CircuitModel/Data/*_EKF_*.mat')\n",
    "np.random.seed(123)\n",
    "#dirlst = glob.glob('/Users/swe/Dropbox (MIT)/CircuitModel/Data/*_EKF_*.mat')\n",
    "filename = dirlst[5]\n",
    "print(filename)\n",
    "beta, alpha, ISI0 = do_beta_alpha_ISI0_fitting(filename, nsamples=100, ntrials=100,\n",
    "                                               betalow=0.0, betahigh=0.9, \n",
    "                                               alphalow=0, alphahigh=0.01, \n",
    "                                               ISI0low=0.500, ISI0high=1.100,\n",
    "                                              sigma=0)\n",
    "\n",
    "sigma = do_sigma_fitting(filename, nsamples=100, ntrials=100,\n",
    "                        sigmalow=0, sigmahigh=0.1, beta=beta, alpha=alpha, ISI0=ISI0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, alpha, ISI0, sigma = subject_fitting(filename, nsamples=100, nsamples2=100, ntrials=100,\n",
    "                    betalow=0, betahigh=0.9, alphalow=0, alphahigh=0.01, ISI0low=0.5, ISI0high=1.1,\n",
    "                    sigmalow=0, sigmahigh=0.1, sigma_init=0, niter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_collection = []\n",
    "for subject_file in dirlst:\n",
    "    print(' ********* Doing subject file %s ************' % subject_file)\n",
    "    combi = subject_fitting(subject_file, nsamples=100, nsamples2=100, ntrials=100,\n",
    "                betalow=0, betahigh=0.9, alphalow=0, alphahigh=0.01, ISI0low=0.5, ISI0high=1.1,\n",
    "                sigmalow=0, sigmahigh=0.1, sigma_init=0, niter=5)\n",
    "    combi_collection.append(combi)\n",
    "    \n",
    "combi_arr = np.array(combi_collection)\n",
    "betas = combi_arr[:,0]\n",
    "alphas = combi_arr[:,1]\n",
    "ISI0s = combi_arr[:,2]\n",
    "sigmas = combi_arr[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.io.savemat('discreteAlgorithm_123Go.mat', \n",
    "                 {'combi_arr': combi_arr, 'filenames': dirlst})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1\n",
    "filename = dirlst[id]\n",
    "print(filename)\n",
    "swedata = scipy.io.loadmat(filename)\n",
    "mtp_in = swedata['mtp_in']\n",
    "stdtp_in = swedata['stdtp_in']\n",
    "\n",
    "beta = combi_arr[id, 0]\n",
    "alpha = combi_arr[id, 1]\n",
    "ISI0 = combi_arr[id, 2]\n",
    "sigma = combi_arr[id , 3]\n",
    "\n",
    "print(alpha,beta,ISI0, sigma)\n",
    "prod_time_lst, prod_std_lst = simulate_123Go_noise(nstages=2,ntrials=100,\n",
    "                                      beta=beta,alpha=alpha,ISI0=ISI0, sigma=sigma)\n",
    "prod_time_lst2, prod_std_lst2 = simulate_123Go_noise(nstages=3,ntrials=100,\n",
    "                                      beta=beta,alpha=alpha,ISI0=ISI0, sigma=sigma)\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.errorbar(ISIs, 1000*prod_time_lst, 1000 * prod_std_lst)\n",
    "plt.errorbar(ISIs, 1000*prod_time_lst2, 1000 * prod_std_lst2)\n",
    "#plt.ylim([600, 1000])\n",
    "plt.title('Model')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.errorbar(ISIs, mtp_in[:,0], stdtp_in[:,0])\n",
    "plt.errorbar(ISIs, mtp_in[:,1], stdtp_in[:,1])\n",
    "plt.ylim([600, 1000])\n",
    "plt.title('Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find subject bias and variance for model\n",
    "mtp_in_all = []\n",
    "stdtp_in_all = []\n",
    "prod_time_lst_all = []\n",
    "prod_std_lst_all = []\n",
    "prod_time_lst2_all = []\n",
    "prod_std_lst2_all = []\n",
    "\n",
    "for id in range(len(dirlst)):\n",
    "    filename = dirlst[id]\n",
    "    print(filename)\n",
    "    swedata = scipy.io.loadmat(filename)\n",
    "    mtp_in = swedata['mtp_in']\n",
    "    stdtp_in = swedata['stdtp_in']\n",
    "\n",
    "    beta = combi_arr[id, 0]\n",
    "    alpha = combi_arr[id, 1]\n",
    "    ISI0 = combi_arr[id, 2]\n",
    "    sigma = combi_arr[id , 3]\n",
    "\n",
    "    print(alpha,beta,ISI0, sigma)\n",
    "    prod_time_lst, prod_std_lst = simulate_123Go_noise(nstages=2,ntrials=100,\n",
    "                                          beta=beta,alpha=alpha,ISI0=ISI0, sigma=sigma)\n",
    "    prod_time_lst2, prod_std_lst2 = simulate_123Go_noise(nstages=3,ntrials=100,\n",
    "                                          beta=beta,alpha=alpha,ISI0=ISI0, sigma=sigma)\n",
    "\n",
    "    # Aggregate the lists\n",
    "    mtp_in_all.append(mtp_in)\n",
    "    stdtp_in_all.append(stdtp_in)\n",
    "    prod_time_lst_all.append(prod_time_lst)\n",
    "    prod_std_lst_all.append(prod_std_lst)\n",
    "    prod_time_lst2_all.append(prod_time_lst2)\n",
    "    prod_std_lst2_all.append(prod_std_lst2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.io.savemat('subject_biasvar_discreteAlgo.mat', \n",
    "                 {'combi_arr': combi_arr, 'filenames': dirlst,\n",
    "                'mtp_in_all': mtp_in_all, 'stdtp_in_all': stdtp_in_all,\n",
    "                'prod_time_lst_all': prod_time_lst_all, 'prod_std_lst_all': prod_std_lst_all,\n",
    "                'prod_time_lst2_all': prod_time_lst2_all, 'prod_std_lst2_all': prod_std_lst2_all})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Continuous time algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def integratorModule(y,I,dt):\n",
    "    y = y + I*dt\n",
    "    \n",
    "    return y\n",
    "\n",
    "def continuousTimeAlgorithm(ISI,beta,alpha,I0,dt):\n",
    "    \n",
    "    totalT = sum(ISI)\n",
    "    t_s = np.zeros(len(ISI)+1)\n",
    "    t_s[1:len(ISI)+1] = np.cumsum(ISI)\n",
    "    t_p = np.zeros(len(ISI)+1)\n",
    "    t_p_ind = 0\n",
    "    t_s_ind = 0\n",
    "    tSteps = int(totalT/dt)\n",
    "    \n",
    "    y_s = np.zeros(tSteps+1)\n",
    "    y_p = np.zeros(tSteps+1)\n",
    "    I = I0*np.ones(tSteps+1)\n",
    "    I[0] = I0\n",
    "    I_p = I\n",
    "    \n",
    "    for ti in range(tSteps):\n",
    "        if t_s[t_s_ind] < ti*dt:\n",
    "            simulatorError = 1 - y_s[ti]\n",
    "            I[ti] = I[ti-1] + beta*simulatorError  # Update input into integrator input\n",
    "            y_s[ti+1] = 0         # Reset simulator on stimulus input\n",
    "            t_s_ind = t_s_ind+1\n",
    "        else:\n",
    "            I[ti] = I[ti-1]\n",
    "            y_s[ti+1] = integratorModule(y_s[ti],I[ti],dt)\n",
    "            \n",
    "        deltaI = alpha*(y_s[ti]-y_p[ti])\n",
    "        I_p[ti] = I[ti]+deltaI\n",
    "        \n",
    "        if y_p[ti] > 1:\n",
    "            t_p[t_p_ind] = ti*dt\n",
    "            t_p_ind = t_p_ind+1\n",
    "            y_p[ti+1] = 0\n",
    "        else:\n",
    "            y_p[ti+1] = integratorModule(y_p[ti],I_p[ti],dt)\n",
    "        \n",
    "        \n",
    "    return y_s, y_p, I, I_p, t_p, t_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ISI = [0.4] * 50\n",
    "y_s, y_p, I, I_p, t_p, t_s = continuousTimeAlgorithm(ISI,beta=0.5,alpha=0,I0=1/0.600,dt=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPI = np.diff(t_p)\n",
    "plt.plot(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
